{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting-Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson you are going to learn about the ***Validation*** set and how it helps the problem of overfitting. \n",
    "\n",
    "> What is overfitting? \n",
    "\n",
    "This is when you create a model that performs very well on your training data (hooray!). But is performs pretty bad on your test data (sad face). The good news is that there are options to deal with this issue.\n",
    "\n",
    "> What is a **validation set**?  \n",
    "\n",
    "Let's recap on the terms we are already familiar with.\n",
    "\n",
    "* Training set - This is the data you will be training your model with.  \n",
    "* Test set - This is the data you will be testing your model with. The test set should not contain data that is in the training set.  \n",
    "\n",
    "> What do we do with the Training set?  \n",
    "\n",
    "This is the data we are going to use to train our model.\n",
    "\n",
    "> What do we do with the Test set?  \n",
    "\n",
    "After training is complete, we try out our model with our Test data. If our model does well, then we did a great job in the training phase. Note that our test data will not contain any of the data we used for training.\n",
    "\n",
    "## So What is a Validation set and why would we want one?  \n",
    "\n",
    "A Validation set is an estimation of the Test set. The Validation set does not contain data from the Training or test set. We use the Validation set during training. Typically what we do is for every N iterations (epochs), we \"test\" our model using the Validation set. We want to see how our model is doing while training and before we run our model through our test data. If the Validation set says we are 95% accurate, then we can say that when we try our model on the Test set, we should get something close to 95% accuracy also. Makes sense?\n",
    "\n",
    "> Any advantages of using a Validation set?  \n",
    "\n",
    "Yes, by using a Validation set one can determine if overfitting is a problem. For example, lets say you started training and you notice your Training error is going down but your Validation error is going up. This is a classic sign that you have an overfitting problem.  \n",
    "\n",
    "> what can I do if I notice that I am overfitting?  \n",
    "\n",
    "As soon as you realize you are starting to overfit, simply stop training. This is called ***early stopping*** and it works great at preventing your model from overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Get to Work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot') # use this plot style\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version 3.6.3 |Anaconda, Inc.| (default, Nov  3 2017, 12:34:11) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "Tensorflow version 1.1.0\n",
      "Pandas version 0.20.3\n",
      "Numpy version 1.12.1\n"
     ]
    }
   ],
   "source": [
    "print('Python version ' + sys.version)\n",
    "print('Tensorflow version ' + tf.VERSION)\n",
    "print('Pandas version ' + pd.__version__)\n",
    "print('Numpy version ' + np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to model\n",
    "\n",
    "    y = a * x^4 + b  \n",
    "\n",
    "\n",
    "> TIP: Recommended percentages  \n",
    "\n",
    "* Training - ***70%***\n",
    "* Validation - ***15%***\n",
    "* Test - ***15%***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate 1000 samples\n",
    "pool = np.random.rand(1000,1).astype(np.float32);\n",
    "\n",
    "#Shuffle samples\n",
    "np.random.shuffle(pool)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "92px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
